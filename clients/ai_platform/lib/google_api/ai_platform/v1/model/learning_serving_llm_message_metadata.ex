# Copyright 2019 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# NOTE: This file is auto generated by the elixir code generator program.
# Do not edit this file manually.

defmodule GoogleApi.AIPlatform.V1.Model.LearningServingLlmMessageMetadata do
  @moduledoc """
  LINT.IfChange This metadata contains additional information required for debugging.

  ## Attributes

  *   `classifierSummary` (*type:* `GoogleApi.AIPlatform.V1.Model.LearningGenaiRootClassifierOutputSummary.t`, *default:* `nil`) - Summary of classifier output. We attach this to all messages regardless of whether classification rules triggered or not.
  *   `codeyOutput` (*type:* `GoogleApi.AIPlatform.V1.Model.LearningGenaiRootCodeyOutput.t`, *default:* `nil`) - Contains metadata related to Codey Processors.
  *   `currentStreamTextLength` (*type:* `integer()`, *default:* `nil`) - 
  *   `deleted` (*type:* `boolean()`, *default:* `nil`) - Whether the corresponding message has been deleted.
  *   `filterMeta` (*type:* `list(GoogleApi.AIPlatform.V1.Model.LearningGenaiRootFilterMetadata.t)`, *default:* `nil`) - Metadata for filters that triggered.
  *   `finalMessageScore` (*type:* `GoogleApi.AIPlatform.V1.Model.LearningGenaiRootScore.t`, *default:* `nil`) - This score is finally used for ranking the message. This will be same as the score present in `Message.score` field.
  *   `finishReason` (*type:* `String.t`, *default:* `nil`) - NOT YET IMPLEMENTED.
  *   `groundingMetadata` (*type:* `GoogleApi.AIPlatform.V1.Model.LearningGenaiRootGroundingMetadata.t`, *default:* `nil`) - 
  *   `isCode` (*type:* `boolean()`, *default:* `nil`) - Applies to streaming response message only. Whether the message is a code.
  *   `isFallback` (*type:* `boolean()`, *default:* `nil`) - Applies to Response message only. Indicates whether the message is a fallback and the response would have otherwise been empty.
  *   `langidResult` (*type:* `GoogleApi.AIPlatform.V1.Model.NlpSaftLangIdResult.t`, *default:* `nil`) - Result from nlp_saft DetectLanguage method. Currently the predicted language code and language probability is used.
  *   `language` (*type:* `String.t`, *default:* `nil`) - Detected language.
  *   `lmPrefix` (*type:* `String.t`, *default:* `nil`) - The LM prefix used to generate this response.
  *   `originalText` (*type:* `String.t`, *default:* `nil`) - The original text generated by LLM. This is the raw output for debugging purposes.
  *   `perStreamDecodedTokenCount` (*type:* `integer()`, *default:* `nil`) - NOT YET IMPLEMENTED. Applies to streaming only. Number of tokens decoded / emitted by the model as part of this stream. This may be different from token_count, which contains number of tokens returned in this response after any response rewriting / truncation.
  *   `raiOutputs` (*type:* `list(GoogleApi.AIPlatform.V1.Model.LearningGenaiRootRAIOutput.t)`, *default:* `nil`) - Results of running RAI on the query or this response candidate. One output per rai_config. It will be populated regardless of whether the threshold is exceeded or not.
  *   `recitationResult` (*type:* `GoogleApi.AIPlatform.V1.Model.LearningGenaiRecitationRecitationResult.t`, *default:* `nil`) - Recitation Results. It will be populated as long as Recitation processing is enabled, regardless of recitation outcome.
  *   `returnTokenCount` (*type:* `integer()`, *default:* `nil`) - NOT YET IMPLEMENTED. Number of tokens returned as part of this candidate.
  *   `scores` (*type:* `list(GoogleApi.AIPlatform.V1.Model.LearningGenaiRootScore.t)`, *default:* `nil`) - All the different scores for a message are logged here.
  *   `streamTerminated` (*type:* `boolean()`, *default:* `nil`) - Whether the response is terminated during streaming return. Only used for streaming requests.
  *   `totalDecodedTokenCount` (*type:* `integer()`, *default:* `nil`) - NOT YET IMPLEMENTED. Aggregated number of total tokens decoded so far. For streaming, this is sum of all the tokens decoded so far i.e. aggregated count.
  *   `translatedUserPrompts` (*type:* `list(String.t)`, *default:* `nil`) - Translated user-prompt used for RAI post processing. This is for internal processing only. We will translate in pre-processor and pass the translated text to the post processor using this field. It will be empty if non of the signals requested need translation.
  *   `vertexRaiResult` (*type:* `GoogleApi.AIPlatform.V1.Model.CloudAiNlLlmProtoServiceRaiResult.t`, *default:* `nil`) - The metadata from Vertex SafetyCat processors
  """

  use GoogleApi.Gax.ModelBase

  @type t :: %__MODULE__{
          :classifierSummary =>
            GoogleApi.AIPlatform.V1.Model.LearningGenaiRootClassifierOutputSummary.t() | nil,
          :codeyOutput => GoogleApi.AIPlatform.V1.Model.LearningGenaiRootCodeyOutput.t() | nil,
          :currentStreamTextLength => integer() | nil,
          :deleted => boolean() | nil,
          :filterMeta =>
            list(GoogleApi.AIPlatform.V1.Model.LearningGenaiRootFilterMetadata.t()) | nil,
          :finalMessageScore => GoogleApi.AIPlatform.V1.Model.LearningGenaiRootScore.t() | nil,
          :finishReason => String.t() | nil,
          :groundingMetadata =>
            GoogleApi.AIPlatform.V1.Model.LearningGenaiRootGroundingMetadata.t() | nil,
          :isCode => boolean() | nil,
          :isFallback => boolean() | nil,
          :langidResult => GoogleApi.AIPlatform.V1.Model.NlpSaftLangIdResult.t() | nil,
          :language => String.t() | nil,
          :lmPrefix => String.t() | nil,
          :originalText => String.t() | nil,
          :perStreamDecodedTokenCount => integer() | nil,
          :raiOutputs => list(GoogleApi.AIPlatform.V1.Model.LearningGenaiRootRAIOutput.t()) | nil,
          :recitationResult =>
            GoogleApi.AIPlatform.V1.Model.LearningGenaiRecitationRecitationResult.t() | nil,
          :returnTokenCount => integer() | nil,
          :scores => list(GoogleApi.AIPlatform.V1.Model.LearningGenaiRootScore.t()) | nil,
          :streamTerminated => boolean() | nil,
          :totalDecodedTokenCount => integer() | nil,
          :translatedUserPrompts => list(String.t()) | nil,
          :vertexRaiResult =>
            GoogleApi.AIPlatform.V1.Model.CloudAiNlLlmProtoServiceRaiResult.t() | nil
        }

  field(:classifierSummary,
    as: GoogleApi.AIPlatform.V1.Model.LearningGenaiRootClassifierOutputSummary
  )

  field(:codeyOutput, as: GoogleApi.AIPlatform.V1.Model.LearningGenaiRootCodeyOutput)
  field(:currentStreamTextLength)
  field(:deleted)

  field(:filterMeta,
    as: GoogleApi.AIPlatform.V1.Model.LearningGenaiRootFilterMetadata,
    type: :list
  )

  field(:finalMessageScore, as: GoogleApi.AIPlatform.V1.Model.LearningGenaiRootScore)
  field(:finishReason)
  field(:groundingMetadata, as: GoogleApi.AIPlatform.V1.Model.LearningGenaiRootGroundingMetadata)
  field(:isCode)
  field(:isFallback)
  field(:langidResult, as: GoogleApi.AIPlatform.V1.Model.NlpSaftLangIdResult)
  field(:language)
  field(:lmPrefix)
  field(:originalText)
  field(:perStreamDecodedTokenCount)
  field(:raiOutputs, as: GoogleApi.AIPlatform.V1.Model.LearningGenaiRootRAIOutput, type: :list)

  field(:recitationResult,
    as: GoogleApi.AIPlatform.V1.Model.LearningGenaiRecitationRecitationResult
  )

  field(:returnTokenCount)
  field(:scores, as: GoogleApi.AIPlatform.V1.Model.LearningGenaiRootScore, type: :list)
  field(:streamTerminated)
  field(:totalDecodedTokenCount)
  field(:translatedUserPrompts, type: :list)
  field(:vertexRaiResult, as: GoogleApi.AIPlatform.V1.Model.CloudAiNlLlmProtoServiceRaiResult)
end

defimpl Poison.Decoder, for: GoogleApi.AIPlatform.V1.Model.LearningServingLlmMessageMetadata do
  def decode(value, options) do
    GoogleApi.AIPlatform.V1.Model.LearningServingLlmMessageMetadata.decode(value, options)
  end
end

defimpl Poison.Encoder, for: GoogleApi.AIPlatform.V1.Model.LearningServingLlmMessageMetadata do
  def encode(value, options) do
    GoogleApi.Gax.ModelBase.encode(value, options)
  end
end
